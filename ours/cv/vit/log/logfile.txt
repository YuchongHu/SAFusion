[1,2]<stdout>:download the dataset
[1,2]<stdout>:load the dataset
[1,2]<stdout>:{'train': '/home/data/mzq/imagenet/train/**', 'validation': '/home/data/mzq/imagenet/val/**'}
[1,3]<stdout>:download the dataset
[1,3]<stdout>:load the dataset
[1,3]<stdout>:{'train': '/home/data/mzq/imagenet/train/**', 'validation': '/home/data/mzq/imagenet/val/**'}
[1,1]<stdout>:download the dataset
[1,1]<stdout>:load the dataset
[1,1]<stdout>:{'train': '/home/data/mzq/imagenet/train/**', 'validation': '/home/data/mzq/imagenet/val/**'}
[1,0]<stdout>:download the dataset
[1,0]<stdout>:load the dataset
[1,0]<stdout>:{'train': '/home/data/mzq/imagenet/train/**', 'validation': '/home/data/mzq/imagenet/val/**'}
[1,2]<stdout>:dataset_column_names =  ['image', 'label']
[1,2]<stdout>:----------------------------------------------
[1,2]<stdout>:Load pretrained model and image processor
[1,2]<stdout>:AutoImageProcessor.from_pretrained
[1,2]<stderr>:Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.
[1,2]<stdout>:AutoModelForImageClassification.from_pretrained
[1,2]<stderr>:Some weights of ViTForImageClassification were not initialized from the model checkpoint at /home/data/mzq/google/vit-large-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']
[1,2]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[1,2]<stdout>:Preprocessing the datasets
[1,2]<stdout>:val_transforms
[1,2]<stdout>:train_dataloader
[1,2]<stdout>:Prepare accelerator
[1,2]<stdout>:Number of parameters: 304326632
[1,2]<stdout>:Total number of tensors: 392
[1,2]<stdout>:Merged number of groups: 21
[1,2]<stdout>:state_time =  1.430511474609375e-06
[1,2]<stdout>:Figure out how many
[1,2]<stdout>:Get the metric function
[1,2]<stdout>:Train!
[1,2]<stdout>:args.with_tracking =  True
[1,1]<stdout>:dataset_column_names =  ['image', 'label']
[1,1]<stdout>:----------------------------------------------
[1,1]<stdout>:Load pretrained model and image processor
[1,1]<stdout>:AutoImageProcessor.from_pretrained
[1,1]<stderr>:Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.
[1,1]<stdout>:AutoModelForImageClassification.from_pretrained
[1,1]<stderr>:Some weights of ViTForImageClassification were not initialized from the model checkpoint at /home/data/mzq/google/vit-large-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']
[1,1]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[1,1]<stdout>:Preprocessing the datasets
[1,1]<stdout>:val_transforms
[1,3]<stdout>:dataset_column_names =  ['image', 'label']
[1,3]<stdout>:----------------------------------------------
[1,3]<stdout>:Load pretrained model and image processor
[1,3]<stdout>:AutoImageProcessor.from_pretrained
[1,3]<stderr>:Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.
[1,3]<stdout>:AutoModelForImageClassification.from_pretrained
[1,3]<stderr>:Some weights of ViTForImageClassification were not initialized from the model checkpoint at /home/data/mzq/google/vit-large-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']
[1,3]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[1,3]<stdout>:Preprocessing the datasets
[1,3]<stdout>:val_transforms
[1,0]<stdout>:time_load_dataset =  441.93103408813477
[1,0]<stdout>:dataset_column_names =  ['image', 'label']
[1,0]<stdout>:----------------------------------------------
[1,0]<stdout>:Load pretrained model and image processor
[1,0]<stdout>:AutoImageProcessor.from_pretrained
[1,0]<stderr>:Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.
[1,0]<stdout>:AutoModelForImageClassification.from_pretrained
[1,1]<stdout>:train_dataloader
[1,1]<stdout>:Prepare accelerator
[1,0]<stderr>:Some weights of ViTForImageClassification were not initialized from the model checkpoint at /home/data/mzq/google/vit-large-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']
[1,0]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[1,0]<stdout>:Preprocessing the datasets
[1,0]<stdout>:val_transforms
[1,1]<stdout>:Number of parameters: 304326632
[1,1]<stdout>:Total number of tensors: 392
[1,1]<stdout>:Merged number of groups: 21
[1,1]<stdout>:state_time =  1.430511474609375e-06
[1,1]<stdout>:Figure out how many
[1,1]<stdout>:Get the metric function
[1,1]<stdout>:Train!
[1,1]<stdout>:args.with_tracking =  True
[1,3]<stdout>:train_dataloader
[1,3]<stdout>:Prepare accelerator
[1,3]<stdout>:Number of parameters: 304326632
[1,3]<stdout>:Total number of tensors: 392
[1,3]<stdout>:Merged number of groups: 21
[1,3]<stdout>:state_time =  9.5367431640625e-07
[1,3]<stdout>:Figure out how many
[1,3]<stdout>:Get the metric function
[1,3]<stdout>:Train!
[1,3]<stdout>:args.with_tracking =  True
[1,0]<stdout>:train_dataloader
[1,0]<stdout>:---args.num_train_epochs:  80000
[1,0]<stdout>:---args.max_train_steps:  800800000
[1,0]<stdout>:---len(train_dataloader):  10010
[1,0]<stdout>:Prepare accelerator
[1,0]<stdout>:Number of parameters: 304326632
[1,0]<stdout>:Total number of tensors: 392
[1,0]<stdout>:Merged number of groups: 21
[1,0]<stdout>:self._group_sizes:  21
[1,0]<stdout>:self._group_sizes:  [[1000, 1024000, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024], [1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024], [1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024], [4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304], [1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024], [1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576], [1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024], [1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024], [1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096], [4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576], [1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024], [1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576], [1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024], [1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304], [4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024], [1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576], [1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024], [1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024], [1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024], [4194304, 4096, 4194304, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1024, 1024, 1024, 1024, 4194304, 4096, 4194304], [1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 1048576, 1024, 786432, 201728, 1024]]
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:19
[1,0]<stdout>:12
[1,0]<stdout>:sum(len(gz))= 392
[1,0]<stdout>:groups_len:  21
[1,0]<stdout>:groups:  [['classifier.bias', 'classifier.weight', 'vit.layernorm.bias', 'vit.layernorm.weight', 'vit.encoder.layer.23.layernorm_after.bias', 'vit.encoder.layer.23.layernorm_after.weight', 'vit.encoder.layer.23.layernorm_before.bias', 'vit.encoder.layer.23.layernorm_before.weight', 'vit.encoder.layer.23.output.dense.bias', 'vit.encoder.layer.23.output.dense.weight', 'vit.encoder.layer.23.intermediate.dense.bias', 'vit.encoder.layer.23.intermediate.dense.weight', 'vit.encoder.layer.23.attention.output.dense.bias', 'vit.encoder.layer.23.attention.output.dense.weight', 'vit.encoder.layer.23.attention.attention.value.bias', 'vit.encoder.layer.23.attention.attention.value.weight', 'vit.encoder.layer.23.attention.attention.key.bias', 'vit.encoder.layer.23.attention.attention.key.weight', 'vit.encoder.layer.23.attention.attention.query.bias'], ['vit.encoder.layer.23.attention.attention.query.weight', 'vit.encoder.layer.22.layernorm_after.bias', 'vit.encoder.layer.22.layernorm_after.weight', 'vit.encoder.layer.22.layernorm_before.bias', 'vit.encoder.layer.22.layernorm_before.weight', 'vit.encoder.layer.22.output.dense.bias', 'vit.encoder.layer.22.output.dense.weight', 'vit.encoder.layer.22.intermediate.dense.bias', 'vit.encoder.layer.22.intermediate.dense.weight', 'vit.encoder.layer.22.attention.output.dense.bias', 'vit.encoder.layer.22.attention.output.dense.weight', 'vit.encoder.layer.22.attention.attention.value.bias', 'vit.encoder.layer.22.attention.attention.value.weight', 'vit.encoder.layer.22.attention.attention.key.bias', 'vit.encoder.layer.22.attention.attention.key.weight', 'vit.encoder.layer.22.attention.attention.query.bias', 'vit.encoder.layer.22.attention.attention.query.weight', 'vit.encoder.layer.21.layernorm_after.bias', 'vit.encoder.layer.21.layernorm_after.weight'], ['vit.encoder.layer.21.layernorm_before.bias', 'vit.encoder.layer.21.layernorm_before.weight', 'vit.encoder.layer.21.output.dense.bias', 'vit.encoder.layer.21.output.dense.weight', 'vit.encoder.layer.21.intermediate.dense.bias', 'vit.encoder.layer.21.intermediate.dense.weight', 'vit.encoder.layer.21.attention.output.dense.bias', 'vit.encoder.layer.21.attention.output.dense.weight', 'vit.encoder.layer.21.attention.attention.value.bias', 'vit.encoder.layer.21.attention.attention.value.weight', 'vit.encoder.layer.21.attention.attention.key.bias', 'vit.encoder.layer.21.attention.attention.key.weight', 'vit.encoder.layer.21.attention.attention.query.bias', 'vit.encoder.layer.21.attention.attention.query.weight', 'vit.encoder.layer.20.layernorm_after.bias', 'vit.encoder.layer.20.layernorm_after.weight', 'vit.encoder.layer.20.layernorm_before.bias', 'vit.encoder.layer.20.layernorm_before.weight', 'vit.encoder.layer.20.output.dense.bias'], ['vit.encoder.layer.20.output.dense.weight', 'vit.encoder.layer.20.intermediate.dense.bias', 'vit.encoder.layer.20.intermediate.dense.weight', 'vit.encoder.layer.20.attention.output.dense.bias', 'vit.encoder.layer.20.attention.output.dense.weight', 'vit.encoder.layer.20.attention.attention.value.bias', 'vit.encoder.layer.20.attention.attention.value.weight', 'vit.encoder.layer.20.attention.attention.key.bias', 'vit.encoder.layer.20.attention.attention.key.weight', 'vit.encoder.layer.20.attention.attention.query.bias', 'vit.encoder.layer.20.attention.attention.query.weight', 'vit.encoder.layer.19.layernorm_after.bias', 'vit.encoder.layer.19.layernorm_after.weight', 'vit.encoder.layer.19.layernorm_before.bias', 'vit.encoder.layer.19.layernorm_before.weight', 'vit.encoder.layer.19.output.dense.bias', 'vit.encoder.layer.19.output.dense.weight', 'vit.encoder.layer.19.intermediate.dense.bias', 'vit.encoder.layer.19.intermediate.dense.weight'], ['vit.encoder.layer.19.attention.output.dense.bias', 'vit.encoder.layer.19.attention.output.dense.weight', 'vit.encoder.layer.19.attention.attention.value.bias', 'vit.encoder.layer.19.attention.attention.value.weight', 'vit.encoder.layer.19.attention.attention.key.bias', 'vit.encoder.layer.19.attention.attention.key.weight', 'vit.encoder.layer.19.attention.attention.query.bias', 'vit.en[1,0]<stdout>:coder.layer.19.attention.attention.query.weight', 'vit.encoder.layer.18.layernorm_after.bias', 'vit.encoder.layer.18.layernorm_after.weight', 'vit.encoder.layer.18.layernorm_before.bias', 'vit.encoder.layer.18.layernorm_before.weight', 'vit.encoder.layer.18.output.dense.bias', 'vit.encoder.layer.18.output.dense.weight', 'vit.encoder.layer.18.intermediate.dense.bias', 'vit.encoder.layer.18.intermediate.dense.weight', 'vit.encoder.layer.18.attention.output.dense.bias', 'vit.encoder.layer.18.attention.output.dense.weight', 'vit.encoder.layer.18.attention.attention.value.bias'], ['vit.encoder.layer.18.attention.attention.value.weight', 'vit.encoder.layer.18.attention.attention.key.bias', 'vit.encoder.layer.18.attention.attention.key.weight', 'vit.encoder.layer.18.attention.attention.query.bias', 'vit.encoder.layer.18.attention.attention.query.weight', 'vit.encoder.layer.17.layernorm_after.bias', 'vit.encoder.layer.17.layernorm_after.weight', 'vit.encoder.layer.17.layernorm_before.bias', 'vit.encoder.layer.17.layernorm_before.weight', 'vit.encoder.layer.17.output.dense.bias', 'vit.encoder.layer.17.output.dense.weight', 'vit.encoder.layer.17.intermediate.dense.bias', 'vit.encoder.layer.17.intermediate.dense.weight', 'vit.encoder.layer.17.attention.output.dense.bias', 'vit.encoder.layer.17.attention.output.dense.weight', 'vit.encoder.layer.17.attention.attention.value.bias', 'vit.encoder.layer.17.attention.attention.value.weight', 'vit.encoder.layer.17.attention.attention.key.bias', 'vit.encoder.layer.17.attention.attention.key.weight'], ['vit.encoder.layer.17.attention.attention.query.bias', 'vit.encoder.layer.17.attention.attention.query.weight', 'vit.encoder.layer.16.layernorm_after.bias', 'vit.encoder.layer.16.layernorm_after.weight', 'vit.encoder.layer.16.layernorm_before.bias', 'vit.encoder.layer.16.layernorm_before.weight', 'vit.encoder.layer.16.output.dense.bias', 'vit.encoder.layer.16.output.dense.weight', 'vit.encoder.layer.16.intermediate.dense.bias', 'vit.encoder.layer.16.intermediate.dense.weight', 'vit.encoder.layer.16.attention.output.dense.bias', 'vit.encoder.layer.16.attention.output.dense.weight', 'vit.encoder.layer.16.attention.attention.value.bias', 'vit.encoder.layer.16.attention.attention.value.weight', 'vit.encoder.layer.16.attention.attention.key.bias', 'vit.encoder.layer.16.attention.attention.key.weight', 'vit.encoder.layer.16.attention.attention.query.bias', 'vit.encoder.layer.16.attention.attention.query.weight', 'vit.encoder.layer.15.layernorm_after.bias'], ['vit.encoder.layer.15.layernorm_after.weight', 'vit.encoder.layer.15.layernorm_before.bias', 'vit.encoder.layer.15.layernorm_before.weight', 'vit.encoder.layer.15.output.dense.bias', 'vit.encoder.layer.15.output.dense.weight', 'vit.encoder.layer.15.intermediate.dense.bias', 'vit.encoder.layer.15.intermediate.dense.weight', 'vit.encoder.layer.15.attention.output.dense.bias', 'vit.encoder.layer.15.attention.output.dense.weight', 'vit.encoder.layer.15.attention.attention.value.bias', 'vit.encoder.layer.15.attention.attention.value.weight', 'vit.encoder.layer.15.attention.attention.key.bias', 'vit.encoder.layer.15.attention.attention.key.weight', 'vit.encoder.layer.15.attention.attention.query.bias', 'vit.encoder.layer.15.attention.attention.query.weight', 'vit.encoder.layer.14.layernorm_after.bias', 'vit.encoder.layer.14.layernorm_after.weight', 'vit.encoder.layer.14.layernorm_before.bias', 'vit.encoder.layer.14.layernorm_before.weight'], ['vit.encoder.layer.14.output.dense.bias', 'vit.encoder.layer.14.output.dense.weight', 'vit.encoder.layer.14.intermediate.dense.bias', 'vit.encoder.layer.14.intermediate.dense.weight', 'vit.encoder.layer.14.attention.output.dense.bias', 'vit.encoder.layer.14.attention.output.dense.weight', 'vit.encoder.layer.14.attention.attention.value.bias', 'vit.encoder.layer.14.attention.attention.value.weight', 'vit.encoder.layer.14.attention.attention.key.bias', 'vit.encoder.layer.14.attention.attention.key.weight', 'vit.encoder.layer.14.attention.attention.query.bias', 'vit.encoder.layer.14.attention.attention.query.weight[1,0]<stdout>:', 'vit.encoder.layer.13.layernorm_after.bias', 'vit.encoder.layer.13.layernorm_after.weight', 'vit.encoder.layer.13.layernorm_before.bias', 'vit.encoder.layer.13.layernorm_before.weight', 'vit.encoder.layer.13.output.dense.bias', 'vit.encoder.layer.13.output.dense.weight', 'vit.encoder.layer.13.intermediate.dense.bias'], ['vit.encoder.layer.13.intermediate.dense.weight', 'vit.encoder.layer.13.attention.output.dense.bias', 'vit.encoder.layer.13.attention.output.dense.weight', 'vit.encoder.layer.13.attention.attention.value.bias', 'vit.encoder.layer.13.attention.attention.value.weight', 'vit.encoder.layer.13.attention.attention.key.bias', 'vit.encoder.layer.13.attention.attention.key.weight', 'vit.encoder.layer.13.attention.attention.query.bias', 'vit.encoder.layer.13.attention.attention.query.weight', 'vit.encoder.layer.12.layernorm_after.bias', 'vit.encoder.layer.12.layernorm_after.weight', 'vit.encoder.layer.12.layernorm_before.bias', 'vit.encoder.layer.12.layernorm_before.weight', 'vit.encoder.layer.12.output.dense.bias', 'vit.encoder.layer.12.output.dense.weight', 'vit.encoder.layer.12.intermediate.dense.bias', 'vit.encoder.layer.12.intermediate.dense.weight', 'vit.encoder.layer.12.attention.output.dense.bias', 'vit.encoder.layer.12.attention.output.dense.weight'], ['vit.encoder.layer.12.attention.attention.value.bias', 'vit.encoder.layer.12.attention.attention.value.weight', 'vit.encoder.layer.12.attention.attention.key.bias', 'vit.encoder.layer.12.attention.attention.key.weight', 'vit.encoder.layer.12.attention.attention.query.bias', 'vit.encoder.layer.12.attention.attention.query.weight', 'vit.encoder.layer.11.layernorm_after.bias', 'vit.encoder.layer.11.layernorm_after.weight', 'vit.encoder.layer.11.layernorm_before.bias', 'vit.encoder.layer.11.layernorm_before.weight', 'vit.encoder.layer.11.output.dense.bias', 'vit.encoder.layer.11.output.dense.weight', 'vit.encoder.layer.11.intermediate.dense.bias', 'vit.encoder.layer.11.intermediate.dense.weight', 'vit.encoder.layer.11.attention.output.dense.bias', 'vit.encoder.layer.11.attention.output.dense.weight', 'vit.encoder.layer.11.attention.attention.value.bias', 'vit.encoder.layer.11.attention.attention.value.weight', 'vit.encoder.layer.11.attention.attention.key.bias'], ['vit.encoder.layer.11.attention.attention.key.weight', 'vit.encoder.layer.11.attention.attention.query.bias', 'vit.encoder.layer.11.attention.attention.query.weight', 'vit.encoder.layer.10.layernorm_after.bias', 'vit.encoder.layer.10.layernorm_after.weight', 'vit.encoder.layer.10.layernorm_before.bias', 'vit.encoder.layer.10.layernorm_before.weight', 'vit.encoder.layer.10.output.dense.bias', 'vit.encoder.layer.10.output.dense.weight', 'vit.encoder.layer.10.intermediate.dense.bias', 'vit.encoder.layer.10.intermediate.dense.weight', 'vit.encoder.layer.10.attention.output.dense.bias', 'vit.encoder.layer.10.attention.output.dense.weight', 'vit.encoder.layer.10.attention.attention.value.bias', 'vit.encoder.layer.10.attention.attention.value.weight', 'vit.encoder.layer.10.attention.attention.key.bias', 'vit.encoder.layer.10.attention.attention.key.weight', 'vit.encoder.layer.10.attention.attention.query.bias', 'vit.encoder.layer.10.attention.attention.query.weight'], ['vit.encoder.layer.9.layernorm_after.bias', 'vit.encoder.layer.9.layernorm_after.weight', 'vit.encoder.layer.9.layernorm_before.bias', 'vit.encoder.layer.9.layernorm_before.weight', 'vit.encoder.layer.9.output.dense.bias', 'vit.encoder.layer.9.output.dense.weight', 'vit.encoder.layer.9.intermediate.dense.bias', 'vit.encoder.layer.9.intermediate.dense.weight', 'vit.encoder.layer.9.attention.output.dense.bias', 'vit.encoder.layer.9.attention.output.dense.weight', 'vit.encoder.layer.9.attention.attention.value.bias', 'vit.encoder.layer.9.attention.attention.value.weight', 'vit.encoder.layer.9.attention.attention.key.bias', 'vit.encoder.layer.9.attention.attention.key.weight', 'vit.encoder.layer.9.attention.attention.query.bias', 'vit.encoder.layer.9.attention.attention.query.weight', 'vit.encoder.layer.8.layernorm_after.bias', 'vit.encoder.lay[1,0]<stdout>:er.8.layernorm_after.weight', 'vit.encoder.layer.8.layernorm_before.bias'], ['vit.encoder.layer.8.layernorm_before.weight', 'vit.encoder.layer.8.output.dense.bias', 'vit.encoder.layer.8.output.dense.weight', 'vit.encoder.layer.8.intermediate.dense.bias', 'vit.encoder.layer.8.intermediate.dense.weight', 'vit.encoder.layer.8.attention.output.dense.bias', 'vit.encoder.layer.8.attention.output.dense.weight', 'vit.encoder.layer.8.attention.attention.value.bias', 'vit.encoder.layer.8.attention.attention.value.weight', 'vit.encoder.layer.8.attention.attention.key.bias', 'vit.encoder.layer.8.attention.attention.key.weight', 'vit.encoder.layer.8.attention.attention.query.bias', 'vit.encoder.layer.8.attention.attention.query.weight', 'vit.encoder.layer.7.layernorm_after.bias', 'vit.encoder.layer.7.layernorm_after.weight', 'vit.encoder.layer.7.layernorm_before.bias', 'vit.encoder.layer.7.layernorm_before.weight', 'vit.encoder.layer.7.output.dense.bias', 'vit.encoder.layer.7.output.dense.weight'], ['vit.encoder.layer.7.intermediate.dense.bias', 'vit.encoder.layer.7.intermediate.dense.weight', 'vit.encoder.layer.7.attention.output.dense.bias', 'vit.encoder.layer.7.attention.output.dense.weight', 'vit.encoder.layer.7.attention.attention.value.bias', 'vit.encoder.layer.7.attention.attention.value.weight', 'vit.encoder.layer.7.attention.attention.key.bias', 'vit.encoder.layer.7.attention.attention.key.weight', 'vit.encoder.layer.7.attention.attention.query.bias', 'vit.encoder.layer.7.attention.attention.query.weight', 'vit.encoder.layer.6.layernorm_after.bias', 'vit.encoder.layer.6.layernorm_after.weight', 'vit.encoder.layer.6.layernorm_before.bias', 'vit.encoder.layer.6.layernorm_before.weight', 'vit.encoder.layer.6.output.dense.bias', 'vit.encoder.layer.6.output.dense.weight', 'vit.encoder.layer.6.intermediate.dense.bias', 'vit.encoder.layer.6.intermediate.dense.weight', 'vit.encoder.layer.6.attention.output.dense.bias'], ['vit.encoder.layer.6.attention.output.dense.weight', 'vit.encoder.layer.6.attention.attention.value.bias', 'vit.encoder.layer.6.attention.attention.value.weight', 'vit.encoder.layer.6.attention.attention.key.bias', 'vit.encoder.layer.6.attention.attention.key.weight', 'vit.encoder.layer.6.attention.attention.query.bias', 'vit.encoder.layer.6.attention.attention.query.weight', 'vit.encoder.layer.5.layernorm_after.bias', 'vit.encoder.layer.5.layernorm_after.weight', 'vit.encoder.layer.5.layernorm_before.bias', 'vit.encoder.layer.5.layernorm_before.weight', 'vit.encoder.layer.5.output.dense.bias', 'vit.encoder.layer.5.output.dense.weight', 'vit.encoder.layer.5.intermediate.dense.bias', 'vit.encoder.layer.5.intermediate.dense.weight', 'vit.encoder.layer.5.attention.output.dense.bias', 'vit.encoder.layer.5.attention.output.dense.weight', 'vit.encoder.layer.5.attention.attention.value.bias', 'vit.encoder.layer.5.attention.attention.value.weight'], ['vit.encoder.layer.5.attention.attention.key.bias', 'vit.encoder.layer.5.attention.attention.key.weight', 'vit.encoder.layer.5.attention.attention.query.bias', 'vit.encoder.layer.5.attention.attention.query.weight', 'vit.encoder.layer.4.layernorm_after.bias', 'vit.encoder.layer.4.layernorm_after.weight', 'vit.encoder.layer.4.layernorm_before.bias', 'vit.encoder.layer.4.layernorm_before.weight', 'vit.encoder.layer.4.output.dense.bias', 'vit.encoder.layer.4.output.dense.weight', 'vit.encoder.layer.4.intermediate.dense.bias', 'vit.encoder.layer.4.intermediate.dense.weight', 'vit.encoder.layer.4.attention.output.dense.bias', 'vit.encoder.layer.4.attention.output.dense.weight', 'vit.encoder.layer.4.attention.attention.value.bias', 'vit.encoder.layer.4.attention.attention.value.weight', 'vit.encoder.layer.4.attention.attention.key.bias', 'vit.encoder.layer.4.attention.attention.key.weight', 'vit.encoder.layer.4.attention.attention.query.bias'],[1,0]<stdout>: ['vit.encoder.layer.4.attention.attention.query.weight', 'vit.encoder.layer.3.layernorm_after.bias', 'vit.encoder.layer.3.layernorm_after.weight', 'vit.encoder.layer.3.layernorm_before.bias', 'vit.encoder.layer.3.layernorm_before.weight', 'vit.encoder.layer.3.output.dense.bias', 'vit.encoder.layer.3.output.dense.weight', 'vit.encoder.layer.3.intermediate.dense.bias', 'vit.encoder.layer.3.intermediate.dense.weight', 'vit.encoder.layer.3.attention.output.dense.bias', 'vit.encoder.layer.3.attention.output.dense.weight', 'vit.encoder.layer.3.attention.attention.value.bias', 'vit.encoder.layer.3.attention.attention.value.weight', 'vit.encoder.layer.3.attention.attention.key.bias', 'vit.encoder.layer.3.attention.attention.key.weight', 'vit.encoder.layer.3.attention.attention.query.bias', 'vit.encoder.layer.3.attention.attention.query.weight', 'vit.encoder.layer.2.layernorm_after.bias', 'vit.encoder.layer.2.layernorm_after.weight'], ['vit.encoder.layer.2.layernorm_before.bias', 'vit.encoder.layer.2.layernorm_before.weight', 'vit.encoder.layer.2.output.dense.bias', 'vit.encoder.layer.2.output.dense.weight', 'vit.encoder.layer.2.intermediate.dense.bias', 'vit.encoder.layer.2.intermediate.dense.weight', 'vit.encoder.layer.2.attention.output.dense.bias', 'vit.encoder.layer.2.attention.output.dense.weight', 'vit.encoder.layer.2.attention.attention.value.bias', 'vit.encoder.layer.2.attention.attention.value.weight', 'vit.encoder.layer.2.attention.attention.key.bias', 'vit.encoder.layer.2.attention.attention.key.weight', 'vit.encoder.layer.2.attention.attention.query.bias', 'vit.encoder.layer.2.attention.attention.query.weight', 'vit.encoder.layer.1.layernorm_after.bias', 'vit.encoder.layer.1.layernorm_after.weight', 'vit.encoder.layer.1.layernorm_before.bias', 'vit.encoder.layer.1.layernorm_before.weight', 'vit.encoder.layer.1.output.dense.bias'], ['vit.encoder.layer.1.output.dense.weight', 'vit.encoder.layer.1.intermediate.dense.bias', 'vit.encoder.layer.1.intermediate.dense.weight', 'vit.encoder.layer.1.attention.output.dense.bias', 'vit.encoder.layer.1.attention.output.dense.weight', 'vit.encoder.layer.1.attention.attention.value.bias', 'vit.encoder.layer.1.attention.attention.value.weight', 'vit.encoder.layer.1.attention.attention.key.bias', 'vit.encoder.layer.1.attention.attention.key.weight', 'vit.encoder.layer.1.attention.attention.query.bias', 'vit.encoder.layer.1.attention.attention.query.weight', 'vit.encoder.layer.0.layernorm_after.bias', 'vit.encoder.layer.0.layernorm_after.weight', 'vit.encoder.layer.0.layernorm_before.bias', 'vit.encoder.layer.0.layernorm_before.weight', 'vit.encoder.layer.0.output.dense.bias', 'vit.encoder.layer.0.output.dense.weight', 'vit.encoder.layer.0.intermediate.dense.bias', 'vit.encoder.layer.0.intermediate.dense.weight'], ['vit.encoder.layer.0.attention.output.dense.bias', 'vit.encoder.layer.0.attention.output.dense.weight', 'vit.encoder.layer.0.attention.attention.value.bias', 'vit.encoder.layer.0.attention.attention.value.weight', 'vit.encoder.layer.0.attention.attention.key.bias', 'vit.encoder.layer.0.attention.attention.key.weight', 'vit.encoder.layer.0.attention.attention.query.bias', 'vit.encoder.layer.0.attention.attention.query.weight', 'vit.embeddings.patch_embeddings.projection.bias', 'vit.embeddings.patch_embeddings.projection.weight', 'vit.embeddings.position_embeddings', 'vit.embeddings.cls_token']]
[1,0]<stdout>:group_dims:  [[1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1], [2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1], [1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1], [2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2], [1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1], [2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], [1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1], [1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1], [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1], [2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2], [1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1], [2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], [1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1], [1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2], [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1], [2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2], [1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1], [2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1], [1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1], [2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2], [1, 2, 1, 2, 1, 2, 1, 2, 1, 4, 3, 3]]
[1,0]<stdout>:state_time =  9.5367431640625e-07
[1,0]<stdout>:state_time =  0.0007848739624023438
[1,0]<stdout>:model.state_dict().keys() =  odict_keys(['vit.embeddings.cls_token', 'vit.embeddings.position_embeddings', 'vit.embeddings.patch_embeddings.projection.weight', 'vit.embeddings.patch_embeddings.projection.bias', 'vit.encoder.layer.0.attention.attention.query.weight', 'vit.encoder.layer.0.attention.attention.query.bias', 'vit.encoder.layer.0.attention.attention.key.weight', 'vit.encoder.layer.0.attention.attention.key.bias', 'vit.encoder.layer.0.attention.attention.value.weight', 'vit.encoder.layer.0.attention.attention.value.bias', 'vit.encoder.layer.0.attention.output.dense.weight', 'vit.encoder.layer.0.attention.output.dense.bias', 'vit.encoder.layer.0.intermediate.dense.weight', 'vit.encoder.layer.0.intermediate.dense.bias', 'vit.encoder.layer.0.output.dense.weight', 'vit.encoder.layer.0.output.dense.bias', 'vit.encoder.layer.0.layernorm_before.weight', 'vit.encoder.layer.0.layernorm_before.bias', 'vit.encoder.layer.0.layernorm_after.weight', 'vit.encoder.layer.0.layernorm_after.bias', 'vit.encoder.layer.1.attention.attention.query.weight', 'vit.encoder.layer.1.attention.attention.query.bias', 'vit.encoder.layer.1.attention.attention.key.weight', 'vit.encoder.layer.1.attention.attention.key.bias', 'vit.encoder.layer.1.attention.attention.value.weight', 'vit.encoder.layer.1.attention.attention.value.bias', 'vit.encoder.layer.1.attention.output.dense.weight', 'vit.encoder.layer.1.attention.output.dense.bias', 'vit.encoder.layer.1.intermediate.dense.weight', 'vit.encoder.layer.1.intermediate.dense.bias', 'vit.encoder.layer.1.output.dense.weight', 'vit.encoder.layer.1.output.dense.bias', 'vit.encoder.layer.1.layernorm_before.weight', 'vit.encoder.layer.1.layernorm_before.bias', 'vit.encoder.layer.1.layernorm_after.weight', 'vit.encoder.layer.1.layernorm_after.bias', 'vit.encoder.layer.2.attention.attention.query.weight', 'vit.encoder.layer.2.attention.attention.query.bias', 'vit.encoder.layer.2.attention.attention.key.weight', 'vit.encoder.layer.2.attention.attention.key.bias', 'vit.encoder.layer.2.attention.attention.value.weight', 'vit.encoder.layer.2.attention.attention.value.bias', 'vit.encoder.layer.2.attention.output.dense.weight', 'vit.encoder.layer.2.attention.output.dense.bias', 'vit.encoder.layer.2.intermediate.dense.weight', 'vit.encoder.layer.2.intermediate.dense.bias', 'vit.encoder.layer.2.output.dense.weight', 'vit.encoder.layer.2.output.dense.bias', 'vit.encoder.layer.2.layernorm_before.weight', 'vit.encoder.layer.2.layernorm_before.bias', 'vit.encoder.layer.2.layernorm_after.weight', 'vit.encoder.layer.2.layernorm_after.bias', 'vit.encoder.layer.3.attention.attention.query.weight', 'vit.encoder.layer.3.attention.attention.query.bias', 'vit.encoder.layer.3.attention.attention.key.weight', 'vit.encoder.layer.3.attention.attention.key.bias', 'vit.encoder.layer.3.attention.attention.value.weight', 'vit.encoder.layer.3.attention.attention.value.bias', 'vit.encoder.layer.3.attention.output.dense.weight', 'vit.encoder.layer.3.attention.output.dense.bias', 'vit.encoder.layer.3.intermediate.dense.weight', 'vit.encoder.layer.3.intermediate.dense.bias', 'vit.encoder.layer.3.output.dense.weight', 'vit.encoder.layer.3.output.dense.bias', 'vit.encoder.layer.3.layernorm_before.weight', 'vit.encoder.layer.3.layernorm_before.bias', 'vit.encoder.layer.3.layernorm_after.weight', 'vit.encoder.layer.3.layernorm_after.bias', 'vit.encoder.layer.4.attention.attention.query.weight', 'vit.encoder.layer.4.attention.attention.query.bias', 'vit.encoder.layer.4.attention.attention.key.weight', 'vit.encoder.layer.4.attention.attention.key.bias', 'vit.encoder.layer.4.attention.attention.value.weight', 'vit.encoder.layer.4.attention.attention.value.bias', 'vit.encoder.layer.4.attention.output.dense.weight', 'vit.encoder.layer.4.attention.output.dense.bias', 'vit.encoder.layer.4.intermediate.dense.weight', 'vit.encoder.layer.4.intermediate.dense.bias', 'vit.encoder.layer.4.output.dense.weight', 'vit.encoder.layer.4.output.dense.bias', 'vit.encoder.layer.4.layernorm_before.weight', 'vit.encoder.layer.4.layernorm_before.bias', 'vit.encoder.l[1,0]<stdout>:ayer.4.layernorm_after.weight', 'vit.encoder.layer.4.layernorm_after.bias', 'vit.encoder.layer.5.attention.attention.query.weight', 'vit.encoder.layer.5.attention.attention.query.bias', 'vit.encoder.layer.5.attention.attention.key.weight', 'vit.encoder.layer.5.attention.attention.key.bias', 'vit.encoder.layer.5.attention.attention.value.weight', 'vit.encoder.layer.5.attention.attention.value.bias', 'vit.encoder.layer.5.attention.output.dense.weight', 'vit.encoder.layer.5.attention.output.dense.bias', 'vit.encoder.layer.5.intermediate.dense.weight', 'vit.encoder.layer.5.intermediate.dense.bias', 'vit.encoder.layer.5.output.dense.weight', 'vit.encoder.layer.5.output.dense.bias', 'vit.encoder.layer.5.layernorm_before.weight', 'vit.encoder.layer.5.layernorm_before.bias', 'vit.encoder.layer.5.layernorm_after.weight', 'vit.encoder.layer.5.layernorm_after.bias', 'vit.encoder.layer.6.attention.attention.query.weight', 'vit.encoder.layer.6.attention.attention.query.bias', 'vit.encoder.layer.6.attention.attention.key.weight', 'vit.encoder.layer.6.attention.attention.key.bias', 'vit.encoder.layer.6.attention.attention.value.weight', 'vit.encoder.layer.6.attention.attention.value.bias', 'vit.encoder.layer.6.attention.output.dense.weight', 'vit.encoder.layer.6.attention.output.dense.bias', 'vit.encoder.layer.6.intermediate.dense.weight', 'vit.encoder.layer.6.intermediate.dense.bias', 'vit.encoder.layer.6.output.dense.weight', 'vit.encoder.layer.6.output.dense.bias', 'vit.encoder.layer.6.layernorm_before.weight', 'vit.encoder.layer.6.layernorm_before.bias', 'vit.encoder.layer.6.layernorm_after.weight', 'vit.encoder.layer.6.layernorm_after.bias', 'vit.encoder.layer.7.attention.attention.query.weight', 'vit.encoder.layer.7.attention.attention.query.bias', 'vit.encoder.layer.7.attention.attention.key.weight', 'vit.encoder.layer.7.attention.attention.key.bias', 'vit.encoder.layer.7.attention.attention.value.weight', 'vit.encoder.layer.7.attention.attention.value.bias', 'vit.encoder.layer.7.attention.output.dense.weight', 'vit.encoder.layer.7.attention.output.dense.bias', 'vit.encoder.layer.7.intermediate.dense.weight', 'vit.encoder.layer.7.intermediate.dense.bias', 'vit.encoder.layer.7.output.dense.weight', 'vit.encoder.layer.7.output.dense.bias', 'vit.encoder.layer.7.layernorm_before.weight', 'vit.encoder.layer.7.layernorm_before.bias', 'vit.encoder.layer.7.layernorm_after.weight', 'vit.encoder.layer.7.layernorm_after.bias', 'vit.encoder.layer.8.attention.attention.query.weight', 'vit.encoder.layer.8.attention.attention.query.bias', 'vit.encoder.layer.8.attention.attention.key.weight', 'vit.encoder.layer.8.attention.attention.key.bias', 'vit.encoder.layer.8.attention.attention.value.weight', 'vit.encoder.layer.8.attention.attention.value.bias', 'vit.encoder.layer.8.attention.output.dense.weight', 'vit.encoder.layer.8.attention.output.dense.bias', 'vit.encoder.layer.8.intermediate.dense.weight', 'vit.encoder.layer.8.intermediate.dense.bias', 'vit.encoder.layer.8.output.dense.weight', 'vit.encoder.layer.8.output.dense.bias', 'vit.encoder.layer.8.layernorm_before.weight', 'vit.encoder.layer.8.layernorm_before.bias', 'vit.encoder.layer.8.layernorm_after.weight', 'vit.encoder.layer.8.layernorm_after.bias', 'vit.encoder.layer.9.attention.attention.query.weight', 'vit.encoder.layer.9.attention.attention.query.bias', 'vit.encoder.layer.9.attention.attention.key.weight', 'vit.encoder.layer.9.attention.attention.key.bias', 'vit.encoder.layer.9.attention.attention.value.weight', 'vit.encoder.layer.9.attention.attention.value.bias', 'vit.encoder.layer.9.attention.output.dense.weight', 'vit.encoder.layer.9.attention.output.dense.bias', 'vit.encoder.layer.9.intermediate.dense.weight', 'vit.encoder.layer.9.intermediate.dense.bias', 'vit.encoder.layer.9.output.dense.weight', 'vit.encoder.layer.9.output.dense.bias', 'vit.encoder.layer.9.layernorm_before.weight', 'vit.encoder.layer.9.layernorm_before.bias', 'vit.encoder.layer.9.layernorm_after.weight', 'vit.encoder.layer.9.layernorm_after.bias', 'vit.encoder.layer.10.attention.attention.query.weight', 'v[1,0]<stdout>:it.encoder.layer.10.attention.attention.query.bias', 'vit.encoder.layer.10.attention.attention.key.weight', 'vit.encoder.layer.10.attention.attention.key.bias', 'vit.encoder.layer.10.attention.attention.value.weight', 'vit.encoder.layer.10.attention.attention.value.bias', 'vit.encoder.layer.10.attention.output.dense.weight', 'vit.encoder.layer.10.attention.output.dense.bias', 'vit.encoder.layer.10.intermediate.dense.weight', 'vit.encoder.layer.10.intermediate.dense.bias', 'vit.encoder.layer.10.output.dense.weight', 'vit.encoder.layer.10.output.dense.bias', 'vit.encoder.layer.10.layernorm_before.weight', 'vit.encoder.layer.10.layernorm_before.bias', 'vit.encoder.layer.10.layernorm_after.weight', 'vit.encoder.layer.10.layernorm_after.bias', 'vit.encoder.layer.11.attention.attention.query.weight', 'vit.encoder.layer.11.attention.attention.query.bias', 'vit.encoder.layer.11.attention.attention.key.weight', 'vit.encoder.layer.11.attention.attention.key.bias', 'vit.encoder.layer.11.attention.attention.value.weight', 'vit.encoder.layer.11.attention.attention.value.bias', 'vit.encoder.layer.11.attention.output.dense.weight', 'vit.encoder.layer.11.attention.output.dense.bias', 'vit.encoder.layer.11.intermediate.dense.weight', 'vit.encoder.layer.11.intermediate.dense.bias', 'vit.encoder.layer.11.output.dense.weight', 'vit.encoder.layer.11.output.dense.bias', 'vit.encoder.layer.11.layernorm_before.weight', 'vit.encoder.layer.11.layernorm_before.bias', 'vit.encoder.layer.11.layernorm_after.weight', 'vit.encoder.layer.11.layernorm_after.bias', 'vit.encoder.layer.12.attention.attention.query.weight', 'vit.encoder.layer.12.attention.attention.query.bias', 'vit.encoder.layer.12.attention.attention.key.weight', 'vit.encoder.layer.12.attention.attention.key.bias', 'vit.encoder.layer.12.attention.attention.value.weight', 'vit.encoder.layer.12.attention.attention.value.bias', 'vit.encoder.layer.12.attention.output.dense.weight', 'vit.encoder.layer.12.attention.output.dense.bias', 'vit.encoder.layer.12.intermediate.dense.weight', 'vit.encoder.layer.12.intermediate.dense.bias', 'vit.encoder.layer.12.output.dense.weight', 'vit.encoder.layer.12.output.dense.bias', 'vit.encoder.layer.12.layernorm_before.weight', 'vit.encoder.layer.12.layernorm_before.bias', 'vit.encoder.layer.12.layernorm_after.weight', 'vit.encoder.layer.12.layernorm_after.bias', 'vit.encoder.layer.13.attention.attention.query.weight', 'vit.encoder.layer.13.attention.attention.query.bias', 'vit.encoder.layer.13.attention.attention.key.weight', 'vit.encoder.layer.13.attention.attention.key.bias', 'vit.encoder.layer.13.attention.attention.value.weight', 'vit.encoder.layer.13.attention.attention.value.bias', 'vit.encoder.layer.13.attention.output.dense.weight', 'vit.encoder.layer.13.attention.output.dense.bias', 'vit.encoder.layer.13.intermediate.dense.weight', 'vit.encoder.layer.13.intermediate.dense.bias', 'vit.encoder.layer.13.output.dense.weight', 'vit.encoder.layer.13.output.dense.bias', 'vit.encoder.layer.13.layernorm_before.weight', 'vit.encoder.layer.13.layernorm_before.bias', 'vit.encoder.layer.13.layernorm_after.weight', 'vit.encoder.layer.13.layernorm_after.bias', 'vit.encoder.layer.14.attention.attention.query.weight', 'vit.encoder.layer.14.attention.attention.query.bias', 'vit.encoder.layer.14.attention.attention.key.weight', 'vit.encoder.layer.14.attention.attention.key.bias', 'vit.encoder.layer.14.attention.attention.value.weight', 'vit.encoder.layer.14.attention.attention.value.bias', 'vit.encoder.layer.14.attention.output.dense.weight', 'vit.encoder.layer.14.attention.output.dense.bias', 'vit.encoder.layer.14.intermediate.dense.weight', 'vit.encoder.layer.14.intermediate.dense.bias', 'vit.encoder.layer.14.output.dense.weight', 'vit.encoder.layer.14.output.dense.bias', 'vit.encoder.layer.14.layernorm_before.weight', 'vit.encoder.layer.14.layern[1,0]<stdout>:orm_before.bias', 'vit.encoder.layer.14.layernorm_after.weight', 'vit.encoder.layer.14.layernorm_after.bias', 'vit.encoder.layer.15.attention.attention.query.weight', 'vit.encoder.layer.15.attention.attention.query.bias', 'vit.encoder.layer.15.attention.attention.key.weight', 'vit.encoder.layer.15.attention.attention.key.bias', 'vit.encoder.layer.15.attention.attention.value.weight', 'vit.encoder.layer.15.attention.attention.value.bias', 'vit.encoder.layer.15.attention.output.dense.weight', 'vit.encoder.layer.15.attention.output.dense.bias', 'vit.encoder.layer.15.intermediate.dense.weight', 'vit.encoder.layer.15.intermediate.dense.bias', 'vit.encoder.layer.15.output.dense.weight', 'vit.encoder.layer.15.output.dense.bias', 'vit.encoder.layer.15.layernorm_before.weight', 'vit.encoder.layer.15.layernorm_before.bias', 'vit.encoder.layer.15.layernorm_after.weight', 'vit.encoder.layer.15.layernorm_after.bias', 'vit.encoder.layer.16.attention.attention.query.weight', 'vit.encoder.layer.16.attention.attention.query.bias', 'vit.encoder.layer.16.attention.attention.key.weight', 'vit.encoder.layer.16.attention.attention.key.bias', 'vit.encoder.layer.16.attention.attention.value.weight', 'vit.encoder.layer.16.attention.attention.value.bias', 'vit.encoder.layer.16.attention.output.dense.weight', 'vit.encoder.layer.16.attention.output.dense.bias', 'vit.encoder.layer.16.intermediate.dense.weight', 'vit.encoder.layer.16.intermediate.dense.bias', 'vit.encoder.layer.16.output.dense.weight', 'vit.encoder.layer.16.output.dense.bias', 'vit.encoder.layer.16.layernorm_before.weight', 'vit.encoder.layer.16.layernorm_before.bias', 'vit.encoder.layer.16.layernorm_after.weight', 'vit.encoder.layer.16.layernorm_after.bias', 'vit.encoder.layer.17.attention.attention.query.weight', 'vit.encoder.layer.17.attention.attention.query.bias', 'vit.encoder.layer.17.attention.attention.key.weight', 'vit.encoder.layer.17.attention.attention.key.bias', 'vit.encoder.layer.17.attention.attention.value.weight', 'vit.encoder.layer.17.attention.attention.value.bias', 'vit.encoder.layer.17.attention.output.dense.weight', 'vit.encoder.layer.17.attention.output.dense.bias', 'vit.encoder.layer.17.intermediate.dense.weight', 'vit.encoder.layer.17.intermediate.dense.bias', 'vit.encoder.layer.17.output.dense.weight', 'vit.encoder.layer.17.output.dense.bias', 'vit.encoder.layer.17.layernorm_before.weight', 'vit.encoder.layer.17.layernorm_before.bias', 'vit.encoder.layer.17.layernorm_after.weight', 'vit.encoder.layer.17.layernorm_after.bias', 'vit.encoder.layer.18.attention.attention.query.weight', 'vit.encoder.layer.18.attention.attention.query.bias', 'vit.encoder.layer.18.attention.attention.key.weight', 'vit.encoder.layer.18.attention.attention.key.bias', 'vit.encoder.layer.18.attention.attention.value.weight', 'vit.encoder.layer.18.attention.attention.value.bias', 'vit.encoder.layer.18.attention.output.dense.weight', 'vit.encoder.layer.18.attention.output.dense.bias', 'vit.encoder.layer.18.intermediate.dense.weight', 'vit.encoder.layer.18.intermediate.dense.bias', 'vit.encoder.layer.18.output.dense.weight', 'vit.encoder.layer.18.output.dense.bias', 'vit.encoder.layer.18.layernorm_before.weight', 'vit.encoder.layer.18.layernorm_before.bias', 'vit.encoder.layer.18.layernorm_after.weight', 'vit.encoder.layer.18.layernorm_after.bias', 'vit.encoder.layer.19.attention.attention.query.weight', 'vit.encoder.layer.19.attention.attention.query.bias', 'vit.encoder.layer.19.attention.attention.key.weight', 'vit.encoder.layer.19.attention.attention.key.bias', 'vit.encoder.layer.19.attention.attention.value.weight', 'vit.encoder.layer.19.attention.attention.value.bias', 'vit.encoder.layer.19.attention.output.dense.weight', 'vit.encoder.layer.19.attention.output.dense.bias', 'vit.encoder.layer.19.intermediate.dense.weight', 'vit.encoder.layer.19.intermediate.dense.bias', 'vit.encoder.layer.19.output.dense.weight', 'vit.encoder.layer.19.output.dense.bias', 'vit.encoder.layer.19.layernorm_before.weight', 'vit.encoder.layer.19.layernorm_before.bias', 'vit.encoder.layer.19.layernorm_after[1,0]<stdout>:.weight', 'vit.encoder.layer.19.layernorm_after.bias', 'vit.encoder.layer.20.attention.attention.query.weight', 'vit.encoder.layer.20.attention.attention.query.bias', 'vit.encoder.layer.20.attention.attention.key.weight', 'vit.encoder.layer.20.attention.attention.key.bias', 'vit.encoder.layer.20.attention.attention.value.weight', 'vit.encoder.layer.20.attention.attention.value.bias', 'vit.encoder.layer.20.attention.output.dense.weight', 'vit.encoder.layer.20.attention.output.dense.bias', 'vit.encoder.layer.20.intermediate.dense.weight', 'vit.encoder.layer.20.intermediate.dense.bias', 'vit.encoder.layer.20.output.dense.weight', 'vit.encoder.layer.20.output.dense.bias', 'vit.encoder.layer.20.layernorm_before.weight', 'vit.encoder.layer.20.layernorm_before.bias', 'vit.encoder.layer.20.layernorm_after.weight', 'vit.encoder.layer.20.layernorm_after.bias', 'vit.encoder.layer.21.attention.attention.query.weight', 'vit.encoder.layer.21.attention.attention.query.bias', 'vit.encoder.layer.21.attention.attention.key.weight', 'vit.encoder.layer.21.attention.attention.key.bias', 'vit.encoder.layer.21.attention.attention.value.weight', 'vit.encoder.layer.21.attention.attention.value.bias', 'vit.encoder.layer.21.attention.output.dense.weight', 'vit.encoder.layer.21.attention.output.dense.bias', 'vit.encoder.layer.21.intermediate.dense.weight', 'vit.encoder.layer.21.intermediate.dense.bias', 'vit.encoder.layer.21.output.dense.weight', 'vit.encoder.layer.21.output.dense.bias', 'vit.encoder.layer.21.layernorm_before.weight', 'vit.encoder.layer.21.layernorm_before.bias', 'vit.encoder.layer.21.layernorm_after.weight', 'vit.encoder.layer.21.layernorm_after.bias', 'vit.encoder.layer.22.attention.attention.query.weight', 'vit.encoder.layer.22.attention.attention.query.bias', 'vit.encoder.layer.22.attention.attention.key.weight', 'vit.encoder.layer.22.attention.attention.key.bias', 'vit.encoder.layer.22.attention.attention.value.weight', 'vit.encoder.layer.22.attention.attention.value.bias', 'vit.encoder.layer.22.attention.output.dense.weight', 'vit.encoder.layer.22.attention.output.dense.bias', 'vit.encoder.layer.22.intermediate.dense.weight', 'vit.encoder.layer.22.intermediate.dense.bias', 'vit.encoder.layer.22.output.dense.weight', 'vit.encoder.layer.22.output.dense.bias', 'vit.encoder.layer.22.layernorm_before.weight', 'vit.encoder.layer.22.layernorm_before.bias', 'vit.encoder.layer.22.layernorm_after.weight', 'vit.encoder.layer.22.layernorm_after.bias', 'vit.encoder.layer.23.attention.attention.query.weight', 'vit.encoder.layer.23.attention.attention.query.bias', 'vit.encoder.layer.23.attention.attention.key.weight', 'vit.encoder.layer.23.attention.attention.key.bias', 'vit.encoder.layer.23.attention.attention.value.weight', 'vit.encoder.layer.23.attention.attention.value.bias', 'vit.encoder.layer.23.attention.output.dense.weight', 'vit.encoder.layer.23.attention.output.dense.bias', 'vit.encoder.layer.23.intermediate.dense.weight', 'vit.encoder.layer.23.intermediate.dense.bias', 'vit.encoder.layer.23.output.dense.weight', 'vit.encoder.layer.23.output.dense.bias', 'vit.encoder.layer.23.layernorm_before.weight', 'vit.encoder.layer.23.layernorm_before.bias', 'vit.encoder.layer.23.layernorm_after.weight', 'vit.encoder.layer.23.layernorm_after.bias', 'vit.layernorm.weight', 'vit.layernorm.bias', 'classifier.weight', 'classifier.bias'])
[1,0]<stdout>:layers_count =  392
[1,0]<stdout>:numel_count =  304326632
[1,0]<stdout>:optimizer.state_dict() =  dict_keys(['state', 'param_groups'])
[1,0]<stdout>:Figure out how many
[1,0]<stdout>:Get the metric function
[1,0]<stdout>:Train!
[1,0]<stdout>:args.with_tracking =  True
[1,0]<stderr>:Train Epoch     #1:   0%|          | 0/10010 [00:00<?, ?it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 1/10010 [00:03<10:29:03,  3.77s/it][1,0]<stderr>:Train Epoch     #1:   0%|          | 2/10010 [00:04<4:57:39,  1.78s/it] [1,0]<stderr>:Train Epoch     #1:   0%|          | 3/10010 [00:04<3:11:42,  1.15s/it][1,0]<stderr>:Train Epoch     #1:   0%|          | 4/10010 [00:04<2:21:53,  1.18it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 5/10010 [00:05<1:54:29,  1.46it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 6/10010 [00:05<1:37:52,  1.70it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 7/10010 [00:06<1:27:18,  1.91it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 8/10010 [00:06<1:20:28,  2.07it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 9/10010 [00:06<1:15:52,  2.20it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 10/10010 [00:07<1:12:41,  2.29it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 11/10010 [00:07<1:10:39,  2.36it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 12/10010 [00:08<1:09:11,  2.41it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 13/10010 [00:08<1:08:03,  2.45it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 14/10010 [00:08<1:07:21,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 15/10010 [00:09<1:06:51,  2.49it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 16/10010 [00:09<1:06:29,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 17/10010 [00:10<1:06:20,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 18/10010 [00:10<1:06:10,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 19/10010 [00:10<1:05:59,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 20/10010 [00:11<1:05:59,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 21/10010 [00:11<1:05:54,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 22/10010 [00:12<1:05:50,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 23/10010 [00:12<1:05:55,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 24/10010 [00:12<1:05:56,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 25/10010 [00:13<1:05:49,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 26/10010 [00:13<1:05:54,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 27/10010 [00:14<1:05:54,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 28/10010 [00:14<1:05:46,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 29/10010 [00:14<1:05:50,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 30/10010 [00:15<1:05:47,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 31/10010 [00:15<1:05:51,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 32/10010 [00:16<1:05:52,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 33/10010 [00:16<1:05:53,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 34/10010 [00:16<1:05:54,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 35/10010 [00:17<1:05:54,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 36/10010 [00:17<1:05:52,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 37/10010 [00:18<1:05:56,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 38/10010 [00:18<1:05:55,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 39/10010 [00:18<1:05:48,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 40/10010 [00:19<1:05:51,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 41/10010 [00:19<1:05:51,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 42/10010 [00:19<1:05:44,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 43/10010 [00:20<1:05:47,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 44/10010 [00:20<1:05:43,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 45/10010 [00:21<1:05:37,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 46/10010 [00:21<1:05:43,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 47/10010 [00:21<1:05:45,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 48/10010 [00:22<1:05:50,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 49/10010 [00:22<1:05:52,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   0%|          | 50/10010 [00:23<1:05:50,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 51/10010 [00:23<1:05:54,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 52/10010 [00:23<1:05:54,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 53/10010 [00:24<1:05:46,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 54/10010 [00:24<1:05:48,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 55/10010 [00:25<1:05:47,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 56/10010 [00:25<1:05:39,  2.53it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 57/10010 [00:25<1:05:46,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 58/10010 [00:26<1:05:52,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 59/10010 [00:26<1:05:46,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 60/10010 [00:27<1:05:48,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 61/10010 [00:27<1:05:47,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 62/10010 [00:27<1:05:42,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 63/10010 [00:28<1:05:45,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 64/10010 [00:28<1:05:45,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 65/10010 [00:29<1:05:49,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 66/10010 [00:29<1:05:50,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 67/10010 [00:29<1:05:43,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 68/10010 [00:30<1:05:47,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 69/10010 [00:30<1:05:47,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 70/10010 [00:31<1:05:42,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 71/10010 [00:31<1:05:42,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 72/10010 [00:31<1:05:41,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 73/10010 [00:32<1:05:49,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 74/10010 [00:32<1:05:51,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 75/10010 [00:33<1:05:47,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 76/10010 [00:33<1:05:44,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 77/10010 [00:33<1:05:50,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 78/10010 [00:34<1:05:48,  2.52it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 79/10010 [00:34<1:05:53,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 80/10010 [00:35<1:05:58,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 81/10010 [00:35<1:05:52,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 82/10010 [00:35<1:05:52,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 83/10010 [00:36<1:05:50,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 84/10010 [00:36<1:05:47,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 85/10010 [00:37<1:05:53,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 86/10010 [00:37<1:05:46,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 87/10010 [00:37<1:05:51,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 88/10010 [00:38<1:05:53,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 89/10010 [00:38<1:05:48,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 90/10010 [00:39<1:05:53,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 91/10010 [00:39<1:06:41,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 92/10010 [00:39<1:06:19,  2.49it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 93/10010 [00:40<1:06:10,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 94/10010 [00:40<1:05:58,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 95/10010 [00:41<1:05:59,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 96/10010 [00:41<1:06:05,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 97/10010 [00:41<1:05:51,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 98/10010 [00:42<1:05:53,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 99/10010 [00:42<1:05:53,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 100/10010 [00:43<1:05:42,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 101/10010 [00:43<1:05:46,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 102/10010 [00:43<1:05:44,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 103/10010 [00:44<1:05:42,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 104/10010 [00:44<1:05:44,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 105/10010 [00:45<1:05:40,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 106/10010 [00:45<1:05:43,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 107/10010 [00:45<1:05:46,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 108/10010 [00:46<1:05:42,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 109/10010 [00:46<1:05:46,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 110/10010 [00:47<1:05:47,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 111/10010 [00:47<1:05:42,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 112/10010 [00:47<1:05:44,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 113/10010 [00:48<1:05:46,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 114/10010 [00:48<1:05:43,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 115/10010 [00:49<1:05:41,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 116/10010 [00:49<1:05:36,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 117/10010 [00:49<1:05:41,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 118/10010 [00:50<1:05:45,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 119/10010 [00:50<1:05:35,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 120/10010 [00:51<1:05:43,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 121/10010 [00:51<1:05:44,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 122/10010 [00:51<1:05:38,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 123/10010 [00:52<1:05:41,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 124/10010 [00:52<1:05:37,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|          | 125/10010 [00:53<1:05:40,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 126/10010 [00:53<1:05:42,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 127/10010 [00:53<1:05:38,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 128/10010 [00:54<1:05:41,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 129/10010 [00:54<1:05:43,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 130/10010 [00:54<1:05:35,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 131/10010 [00:55<1:05:45,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 132/10010 [00:55<1:05:43,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 133/10010 [00:56<1:05:34,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 134/10010 [00:56<1:05:36,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 135/10010 [00:56<1:05:38,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 136/10010 [00:57<1:05:36,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 137/10010 [00:57<1:05:40,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 138/10010 [00:58<1:05:38,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 139/10010 [00:58<1:05:33,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 140/10010 [00:58<1:05:39,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 141/10010 [00:59<1:05:34,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 142/10010 [00:59<1:05:38,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 143/10010 [01:00<1:05:41,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 144/10010 [01:00<1:05:36,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 145/10010 [01:00<1:05:39,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 146/10010 [01:01<1:05:37,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 147/10010 [01:01<1:05:31,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 148/10010 [01:02<1:05:36,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 149/10010 [01:02<1:05:33,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   1%|         | 150/10010 [01:02<1:05:30,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 151/10010 [01:03<1:05:34,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 152/10010 [01:03<1:05:29,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 153/10010 [01:04<1:05:32,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 154/10010 [01:04<1:05:41,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 155/10010 [01:04<1:05:31,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 156/10010 [01:05<1:05:35,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 157/10010 [01:05<1:05:36,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 158/10010 [01:06<1:05:40,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 159/10010 [01:06<1:05:44,  2.50it/s][1,2]<stderr>:/home/mzq/anaconda3/envs/py39bert/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:863: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. 
[1,2]<stderr>:  warnings.warn(str(msg))
[1,0]<stderr>:Train Epoch     #1:   2%|         | 160/10010 [01:06<1:05:36,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 161/10010 [01:07<1:05:40,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 162/10010 [01:07<1:05:44,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 163/10010 [01:08<1:05:40,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 164/10010 [01:08<1:05:43,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 165/10010 [01:08<1:05:46,  2.49it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 166/10010 [01:09<1:05:36,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 167/10010 [01:09<1:05:40,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 168/10010 [01:10<1:05:36,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 169/10010 [01:10<1:05:37,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 170/10010 [01:10<1:05:41,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 171/10010 [01:11<1:05:37,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 172/10010 [01:11<1:05:38,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 173/10010 [01:12<1:05:39,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 174/10010 [01:12<1:05:33,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 175/10010 [01:12<1:05:35,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 176/10010 [01:13<1:05:34,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 177/10010 [01:13<1:05:26,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 178/10010 [01:14<1:05:30,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 179/10010 [01:14<1:05:34,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 180/10010 [01:14<1:05:27,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 181/10010 [01:15<1:05:30,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 182/10010 [01:15<1:05:25,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 183/10010 [01:16<1:05:25,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 184/10010 [01:16<1:05:26,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 185/10010 [01:16<1:05:23,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 186/10010 [01:17<1:05:24,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 187/10010 [01:17<1:05:23,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 188/10010 [01:18<1:05:17,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 189/10010 [01:18<1:05:21,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 190/10010 [01:18<1:05:18,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 191/10010 [01:19<1:05:19,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 192/10010 [01:19<1:05:24,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 193/10010 [01:20<1:05:27,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 194/10010 [01:20<1:05:29,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 195/10010 [01:20<1:05:29,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 196/10010 [01:21<1:05:28,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 197/10010 [01:21<1:05:29,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 198/10010 [01:22<1:05:23,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 199/10010 [01:22<1:05:19,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 200/10010 [01:22<1:05:18,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 201/10010 [01:23<1:05:14,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 202/10010 [01:23<1:05:17,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 203/10010 [01:24<1:05:17,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 204/10010 [01:24<1:05:14,  2.51it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 205/10010 [01:24<1:05:18,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 206/10010 [01:25<1:05:17,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 207/10010 [01:25<1:05:19,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 208/10010 [01:26<1:05:18,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 209/10010 [01:26<1:05:19,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 210/10010 [01:26<1:05:21,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 211/10010 [01:27<1:05:23,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 212/10010 [01:27<1:05:17,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 213/10010 [01:28<1:05:21,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 214/10010 [01:28<1:05:19,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 215/10010 [01:28<1:05:18,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 216/10010 [01:29<1:05:19,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 217/10010 [01:29<1:05:16,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 218/10010 [01:30<1:05:22,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 219/10010 [01:30<1:05:24,  2.49it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 220/10010 [01:30<1:05:15,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 221/10010 [01:31<1:05:19,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 222/10010 [01:31<1:05:14,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 223/10010 [01:32<1:05:20,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 224/10010 [01:32<1:05:19,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 225/10010 [01:32<1:05:11,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 226/10010 [01:33<1:05:13,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 227/10010 [01:33<1:05:13,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 228/10010 [01:34<1:05:07,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 229/10010 [01:34<1:05:10,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 230/10010 [01:34<1:05:08,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 231/10010 [01:35<1:05:12,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 232/10010 [01:35<1:05:12,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 233/10010 [01:36<1:05:10,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 234/10010 [01:36<1:05:10,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 235/10010 [01:36<1:05:08,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 236/10010 [01:37<1:05:04,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 237/10010 [01:37<1:05:10,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 238/10010 [01:38<1:05:09,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 239/10010 [01:38<1:05:11,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 240/10010 [01:38<1:05:15,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 241/10010 [01:39<1:05:08,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 242/10010 [01:39<1:05:08,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 243/10010 [01:40<1:05:06,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 244/10010 [01:40<1:05:12,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 245/10010 [01:40<1:05:13,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 246/10010 [01:41<1:05:07,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 247/10010 [01:41<1:05:14,  2.49it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 248/10010 [01:42<1:05:13,  2.49it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 249/10010 [01:42<1:05:03,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   2%|         | 250/10010 [01:42<1:05:08,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 251/10010 [01:43<1:05:06,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 252/10010 [01:43<1:05:06,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 253/10010 [01:44<1:05:10,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 254/10010 [01:44<1:05:03,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 255/10010 [01:44<1:05:05,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 256/10010 [01:45<1:05:02,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 257/10010 [01:45<1:04:59,  2.50it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 258/10010 [01:46<1:05:19,  2.49it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 259/10010 [01:46<1:05:31,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 260/10010 [01:46<1:05:45,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 261/10010 [01:47<1:05:46,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 262/10010 [01:47<1:05:45,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 263/10010 [01:48<1:05:44,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 264/10010 [01:48<1:05:39,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 265/10010 [01:49<1:05:44,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 266/10010 [01:49<1:05:41,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 267/10010 [01:49<1:05:34,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 268/10010 [01:50<1:05:40,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 269/10010 [01:50<1:05:29,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 270/10010 [01:51<1:05:32,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 271/10010 [01:51<1:05:33,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 272/10010 [01:51<1:05:35,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 273/10010 [01:52<1:05:39,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 274/10010 [01:52<1:05:30,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 275/10010 [01:53<1:05:32,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 276/10010 [01:53<1:05:29,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 277/10010 [01:53<1:05:35,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 278/10010 [01:54<1:05:38,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 279/10010 [01:54<1:05:33,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 280/10010 [01:55<1:05:35,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 281/10010 [01:55<1:05:29,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 282/10010 [01:55<1:05:34,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 283/10010 [01:56<1:05:39,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 284/10010 [01:56<1:05:30,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 285/10010 [01:57<1:05:34,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 286/10010 [01:57<1:05:32,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 287/10010 [01:57<1:05:34,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 288/10010 [01:58<1:05:31,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 289/10010 [01:58<1:05:28,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 290/10010 [01:59<1:05:27,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 291/10010 [01:59<1:05:25,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 292/10010 [01:59<1:05:24,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 293/10010 [02:00<1:05:27,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 294/10010 [02:00<1:05:25,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 295/10010 [02:01<1:05:28,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 296/10010 [02:01<1:05:29,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 297/10010 [02:01<1:05:27,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 298/10010 [02:02<1:05:30,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 299/10010 [02:02<1:05:27,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 300/10010 [02:03<1:05:28,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 301/10010 [02:03<1:05:28,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 302/10010 [02:03<1:05:21,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 303/10010 [02:04<1:05:24,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 304/10010 [02:04<1:05:21,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 305/10010 [02:05<1:05:25,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 306/10010 [02:05<1:05:27,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 307/10010 [02:05<1:05:19,  2.48it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 308/10010 [02:06<1:05:25,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 309/10010 [02:06<1:05:24,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 310/10010 [02:07<1:05:34,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 311/10010 [02:07<1:05:31,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 312/10010 [02:08<1:05:23,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 313/10010 [02:08<1:05:23,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 314/10010 [02:08<1:05:20,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 315/10010 [02:09<1:05:21,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 316/10010 [02:09<1:05:24,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 317/10010 [02:10<1:05:18,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 318/10010 [02:10<1:05:18,  2.47it/s][1,0]<stderr>:Train Epoch     #1:   3%|         | 319/10010 [02:10<1:05:16,  2.47it/s]